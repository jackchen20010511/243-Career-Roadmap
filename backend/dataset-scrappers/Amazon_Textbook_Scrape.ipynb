{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f7caf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "def clean_amazon_url(url):\n",
    "    try:\n",
    "        # Amazon base URL\n",
    "        amazon_base_url = \"https://www.amazon.com\"\n",
    "\n",
    "        # Convert relative to absolute URL if needed\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = amazon_base_url + url\n",
    "\n",
    "        # Parse the URL\n",
    "        parsed_url = urlparse(url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "\n",
    "        # Case 1: Sponsored Ad Link (Redirect)\n",
    "        if 'url' in query_params:\n",
    "            # Extract the actual product URL from \"url\" parameter\n",
    "            actual_url = unquote(query_params['url'][0])\n",
    "            return clean_amazon_url(amazon_base_url + actual_url)\n",
    "\n",
    "        # Case 2: Direct Product URL\n",
    "        path_parts = parsed_url.path.split('/')\n",
    "        if 'dp' in path_parts:\n",
    "            asin_index = path_parts.index('dp') + 1\n",
    "            asin = path_parts[asin_index] if asin_index < len(path_parts) else None\n",
    "\n",
    "            if asin:\n",
    "                # Construct the clean product link\n",
    "                clean_url = f\"{amazon_base_url}/dp/{asin}\"\n",
    "                return clean_url\n",
    "            else:\n",
    "                raise ValueError(\"ASIN not found in URL.\")\n",
    "\n",
    "        raise ValueError(\"Invalid Amazon product URL format.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39197340",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = \"C:/Users/jackc/chromedriver-win64/chromedriver.exe\"\n",
    "service = Service(driver_path)\n",
    "\n",
    "# Initialize the WebDriver\n",
    "browser = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ad0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the webpage\n",
    "browser.get(\"https://www.amazon.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95b2720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 1 1 Python.csv saved at: textbook_data\\Python.csv\n",
      "\n",
      "-----------------------Progress(1/9481)--------------------\n",
      "max 1 1 Java.csv saved at: textbook_data\\Java.csv\n",
      "\n",
      "-----------------------Progress(2/9481)--------------------\n",
      "max 1 1 Sql.csv saved at: textbook_data\\Sql.csv\n",
      "\n",
      "-----------------------Progress(3/9481)--------------------\n",
      "max 1 1 Aws.csv saved at: textbook_data\\Aws.csv\n",
      "\n",
      "-----------------------Progress(4/9481)--------------------\n",
      "max 1 1 Machine Learning.csv saved at: textbook_data\\Machine Learning.csv\n",
      "\n",
      "-----------------------Progress(5/9481)--------------------\n",
      "max 1 1 JS.csv saved at: textbook_data\\JS.csv\n",
      "\n",
      "-----------------------Progress(6/9481)--------------------\n",
      "max 1 1 C++.csv saved at: textbook_data\\C++.csv\n",
      "\n",
      "-----------------------Progress(7/9481)--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m     input_searchs[\u001b[32m0\u001b[39m].send_keys(skill+\u001b[33m\"\u001b[39m\u001b[33m Book\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m     search_buttons[\u001b[32m0\u001b[39m].click()\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     time.sleep(random.randint(\u001b[32m2\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     36\u001b[39m     dataset.append(data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Output folder for saving HTML files\n",
    "data_folder = \"textbook_data\"\n",
    "os.makedirs(data_folder, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# Search skills: what skills do you want to get course data on\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# Specify the path to the file containing the extracted skills\n",
    "file_path = './all_skills.txt'\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    skills = file.readlines()  # Read each line as an individual skill\n",
    "tech_skills = [skill.strip() for skill in skills]\n",
    "\n",
    "latest_skill_index = 0\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# List of URLs to scrape\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "dataset = []\n",
    "for idx, skill in enumerate(tech_skills[latest_skill_index:]):\n",
    "    count = 0\n",
    "    data = []\n",
    "    # Find search bar and input and click\n",
    "    \n",
    "    input_searchs = browser.find_elements(By.ID, \"twotabsearchtextbox\")\n",
    "    search_buttons = browser.find_elements(By.ID, \"nav-search-submit-button\")\n",
    "    if input_searchs and search_buttons:\n",
    "        input_searchs[0].clear()\n",
    "        input_searchs[0].send_keys(skill+\" Book\")\n",
    "        search_buttons[0].click()\n",
    "        time.sleep(random.randint(2,3))\n",
    "    else:\n",
    "        dataset.append(data)\n",
    "        continue\n",
    "    # Find all book elements in this page\n",
    "    product_buttons = browser.find_elements(By.CSS_SELECTOR, 'div[data-cy=\"title-recipe\"] a.a-link-normal.s-link-style.a-text-normal')\n",
    "    max_count = min(1, len(product_buttons)) if product_buttons else 0\n",
    "    \n",
    "    print(f\"max {max_count} \", end=\"\")\n",
    "    while max_count > count:\n",
    "        print(f\"{count+1} \", end=\"\")\n",
    "        product_buttons = browser.find_elements(By.CSS_SELECTOR, 'div[data-cy=\"title-recipe\"] a.a-link-normal.s-link-style.a-text-normal')\n",
    "        if product_buttons and len(product_buttons) > count:\n",
    "            head = \"https://www.amazon.com\"\n",
    "            link = head + browser.execute_script(\"return arguments[0].getAttribute('href');\", product_buttons[count])\\\n",
    "                  if browser.execute_script(\"return arguments[0].getAttribute('href');\", product_buttons[count]) else None\n",
    "            browser.execute_script(\"document.activeElement.blur();\")\n",
    "            time.sleep(1)\n",
    "            product_buttons[count].click()\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            data.append({\n",
    "                'skill': None,\n",
    "                'link': None,\n",
    "                'image_link': None,\n",
    "                'author': None,\n",
    "                'title': None,\n",
    "                'price': None,\n",
    "                'publisher': None,\n",
    "                'language': None,\n",
    "                'num_page': None,\n",
    "                'isbn': None,\n",
    "                'rankings': None,\n",
    "                'rating': None,\n",
    "                'num_rating': None\n",
    "            })\n",
    "            count += 1\n",
    "            continue\n",
    "            \n",
    "        title_elements = browser.find_elements(By.CSS_SELECTOR, 'div.a-section.a-spacing-none h1#title span#productTitle')\n",
    "        title= browser.execute_script(\"return arguments[0].textContent;\", title_elements[0])\\\n",
    "        if title_elements else None\n",
    "        \n",
    "        price_elements = browser.find_elements(By.CSS_SELECTOR,\\\n",
    "                        'div#buybox div.a-section.a-spacing-none.aok-align-center.aok-relative span.aok-offscreen')\n",
    "        price = browser.execute_script(\"return arguments[0].textContent;\", price_elements[0])\\\n",
    "        if price_elements else None\n",
    "\n",
    "        img_elements = browser.find_elements(By.CSS_SELECTOR, 'span.a-declarative div#imgTagWrapperId.imgTagWrapper img#landingImage')\n",
    "        img_link = browser.execute_script(\"return arguments[0].getAttribute('src');\", img_elements[0])\\\n",
    "        if img_elements else None\n",
    "        \n",
    "        author_elements = browser.find_elements(By.CSS_SELECTOR,\\\n",
    "                    'div#bylineInfo span.author.notFaded a.a-link-normal')\n",
    "        author = browser.execute_script(\"return arguments[0].textContent;\", author_elements[0])\\\n",
    "        if author_elements else None\n",
    "        \n",
    "        product_details = browser.find_elements(By.CSS_SELECTOR, \"div#detailBulletsWrapper_feature_div\")\n",
    "        alists = product_details[0].find_elements(By.CSS_SELECTOR, \"div#detailBullets_feature_div li span.a-list-item\") if product_details else None\n",
    "        publisher, language, num_page, isbn = (None, None, None, None)\n",
    "        if alists:\n",
    "            for span in alists:\n",
    "                category_elements = span.find_elements(By.CSS_SELECTOR, \"span\")\n",
    "                category = browser.execute_script(\"return arguments[0].textContent;\", category_elements[0])\\\n",
    "                if category_elements else None\n",
    "                info = browser.execute_script(\"return arguments[0].textContent;\", category_elements[-1])\\\n",
    "                if category_elements else None\n",
    "                if category and \"Publisher\" in category:\n",
    "                    publisher = info\n",
    "                elif category and \"Language\" in category:\n",
    "                    language = info\n",
    "                elif category and \"Paperback\" in category:\n",
    "                    num_page = info\n",
    "                elif category and \"ISBN\" in category:\n",
    "                    isbn = info\n",
    "\n",
    "        # Find the ranking list\n",
    "        rank_elements = browser.find_elements(By.CSS_SELECTOR, \"ul.a-unordered-list.a-nostyle.a-vertical.zg_hrsr li\")\n",
    "\n",
    "        # Extract the ranking and category using JavaScript\n",
    "        rankings = []\n",
    "        if rank_elements:\n",
    "            for rank in rank_elements:\n",
    "                # Get full text using JavaScript\n",
    "                full_text = browser.execute_script(\"return arguments[0].textContent;\", rank).strip()\n",
    "\n",
    "                # Extract the ranking number and category\n",
    "                if \" in \" in full_text:\n",
    "                    number, category = full_text.split(\" in \", 1)\n",
    "                    number = int(number.replace(\"#\", \"\").replace(\",\", \"\").strip())\n",
    "                    category = category.strip()\n",
    "                    rankings.append((number, category))\n",
    "        rating_elements = browser.find_elements(By.CSS_SELECTOR, \"div#averageCustomerReviews_feature_div.celwidget\")\n",
    "        rating_tags = rating_elements[0].find_elements(By.CSS_SELECTOR, \"span#acrPopover span.a-size-base.a-color-base\")\\\n",
    "        if rating_elements else None\n",
    "        rating = browser.execute_script(\"return arguments[0].textContent;\", rating_tags[0])\\\n",
    "                if rating_tags else None\n",
    "        num_rating_tags = rating_elements[0].find_elements(By.CSS_SELECTOR, \"span#acrCustomerReviewText.a-size-base\")\\\n",
    "        if rating_elements else None\n",
    "        num_rating = browser.execute_script(\"return arguments[0].textContent;\", num_rating_tags[0])\\\n",
    "                if num_rating_tags else None\n",
    "        new = {\n",
    "                'skill': skill,\n",
    "                'link': link,\n",
    "                'image_link': img_link,\n",
    "                'author': author,\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'publisher': publisher,\n",
    "                'language': language,\n",
    "                'num_page': num_page,\n",
    "                'isbn': isbn,\n",
    "                'rankings': rankings,\n",
    "                'rating': rating,\n",
    "                'num_rating': num_rating\n",
    "            }\n",
    "        if new not in data:\n",
    "            data.append(new)\n",
    "        browser.back()\n",
    "        count += 1\n",
    "    df = pd.DataFrame(data)\n",
    "    skillname = skill.replace(\"/\", \"_\").replace(\"*\", \"_\")\n",
    "    csv_path = os.path.join(data_folder, f\"{skillname}.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"{skillname}.csv saved at: {csv_path}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"-----------------------Progress({latest_skill_index+idx+1}/{len(tech_skills)})--------------------\")\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
