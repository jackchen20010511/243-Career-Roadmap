{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd3e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "from scipy.stats import binom\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import defaultdict\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890d1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Wilson Score Interval to correct ranking\n",
    "def wilson_score(rating, num_reviews, confidence=1.9):\n",
    "    \"\"\"Computes Wilson Score for a course based on its rating and number of reviews.\"\"\"\n",
    "    if num_reviews == 0:\n",
    "        return 0  # If no reviews, lowest possible score\n",
    "\n",
    "    p_hat = rating / 5  # Convert rating scale to [0,1]\n",
    "    n = num_reviews\n",
    "\n",
    "    denominator = 1 + (confidence ** 2 / n)\n",
    "    center_adj = p_hat + (confidence ** 2 / (2 * n))\n",
    "    margin = confidence * ((p_hat * (1 - p_hat) / n) + (confidence ** 2 / (4 * n ** 2))) ** 0.5\n",
    "\n",
    "    wilson_lower_bound = (center_adj - margin) / denominator\n",
    "    return wilson_lower_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4070c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid or empty file: DevOps Engineer_unix_linux.csv\n",
      "Skipping invalid or empty file: Java Developer_unix.csv\n",
      "Skipping invalid or empty file: Project Manager_linux operating system.csv\n",
      "Skipping invalid or empty file: Project Manager_machine learning.csv\n",
      "Skipping invalid or empty file: Software Development Engineer in Test (SDET)_db2.csv\n",
      "Skipping invalid or empty file: Software Development Engineer in Test (SDET)_windows server.csv\n",
      "Skipping invalid or empty file: Software Engineer_ms sql server.csv\n",
      "Skipping invalid or empty file: Web Developer_api's.csv\n",
      "Skipping invalid or empty file: Web Developer_restful api's.csv\n"
     ]
    }
   ],
   "source": [
    "# Set your data directory\n",
    "data_dir = \"./udemy_data\"\n",
    "\n",
    "# Dictionary to collect all DataFrames per job title\n",
    "job_title_dfs = defaultdict(list)\n",
    "\n",
    "# Loop through all files\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Extract job title from file name\n",
    "        job_title = filename.split(\"_\")[0]  # or use a better parser if needed\n",
    "\n",
    "        # Read CSV\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            if df.empty:\n",
    "                print(f\"Skipping empty file: {filename}\")\n",
    "                continue\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping invalid or empty file: {filename}\")\n",
    "            continue\n",
    "\n",
    "        # Append to the job_title's list\n",
    "        job_title_dfs[job_title].append(df)\n",
    "\n",
    "# Combine and save for each job title\n",
    "output_dir = \"./udemy_df\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for job_title, dfs in job_title_dfs.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    output_path = os.path.join(output_dir, f\"{job_title}.csv\")\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48c48f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coursera Data Cleaning and None Values Handling\n",
    "\n",
    "data_dir = \"./coursera_df\"\n",
    "\n",
    "# Loop through all files\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        \n",
    "        job_title = filename.split(\".\")[0]\n",
    "\n",
    "        df_coursera = pd.read_csv(f\"{data_dir}/{filename}\")\n",
    "\n",
    "        def convert_to_hours(duration):\n",
    "            duration = duration.lower().strip()  # Normalize text\n",
    "            \n",
    "            # Match different patterns\n",
    "            match = re.search(r'(\\d+)\\s*-\\s*(\\d+)\\s*(weeks|months|years|meses|hours)', duration)\n",
    "            single_match = re.search(r'(\\d+)\\s*(weeks|months|years|meses|hours)', duration)\n",
    "            # Handle ranges\n",
    "            if match:\n",
    "                num1, num2, unit = int(match.group(1)), int(match.group(2)), match.group(3)\n",
    "            elif single_match:\n",
    "                num1, num2, unit = int(single_match.group(1)), int(single_match.group(1)), single_match.group(2)\n",
    "            else:\n",
    "                return None\n",
    "            # Convert to days\n",
    "            if \"week\" in unit:\n",
    "                hours = 10 * num1\n",
    "            elif \"month\" in unit or \"mes\" in unit:\n",
    "                hours = 10 * num1 * 4\n",
    "            elif \"year\" in unit:\n",
    "                hours = 10 * num1 * 52\n",
    "            elif \"hour\" in unit:\n",
    "                hours = num1\n",
    "            return hours\n",
    "\n",
    "        # Function to safely convert string lists to actual Python lists\n",
    "        def str_to_list(value):\n",
    "            if isinstance(value, str):\n",
    "                return ast.literal_eval(value)  # Convert string to list\n",
    "            else:\n",
    "                return []  # Handle NaN or other types by returning an empty list\n",
    "\n",
    "        df_coursera[\"course_skill\"] = df_coursera[\"course_skill\"].apply(str_to_list)\n",
    "\n",
    "        # Change num_review to int type\n",
    "        df_coursera[\"num_review\"] = df_coursera[\"num_review\"].fillna(0).astype(int)\n",
    "\n",
    "        # Map difficulty to numeric\n",
    "        difficulty_mapping = {\n",
    "            'Beginner': 1,\n",
    "            'Intermediate': 2,\n",
    "            'Mixed': 1.5,\n",
    "            'Advanced': 3,\n",
    "            'All Levels': 1.5\n",
    "        }\n",
    "        df_coursera['difficulty'] = df_coursera['difficulty'].fillna(\"Mixed\")\n",
    "        df_coursera['difficulty_numeric'] = df_coursera['difficulty'].fillna(\"Mixed\").map(difficulty_mapping)\n",
    "\n",
    "        course_type_str = [\"Course\", \"Professional Certificate\"]\n",
    "        mask = ~df_coursera['course_type'].isin(course_type_str)\n",
    "        # Change incorrect course_type to Course\n",
    "        df_coursera.loc[mask, 'course_type'] = \"Course\"\n",
    "        df_coursera.loc[df_coursera['course_type'] == \"Professional Certificate\", 'course_type'] = \"Certificate\"\n",
    "        df_coursera.loc[df_coursera['course_type'] == \"Certificate\", 'difficulty_numeric'] = 3.0\n",
    "\n",
    "\n",
    "        # Convert duration string into min max int in days\n",
    "        df_coursera['duration'] = df_coursera['duration'].fillna(df_coursera['duration'].mode()[0])\n",
    "        df_coursera['duration'] = df_coursera['duration'].apply(convert_to_hours)\n",
    "\n",
    "        df_coursera[\"price\"] = df_coursera[\"duration\"] * 59/30/5\n",
    "\n",
    "        # Fill None course skill with skill\n",
    "        df_coursera[\"description\"] = df_coursera[\"course_skill\"].fillna(df_coursera[\"skill\"])\n",
    "\n",
    "        # Fill None rating with average rating\n",
    "        df_coursera[\"rating\"] = df_coursera[\"rating\"].fillna(df_coursera[\"rating\"].mean())\n",
    "        df_coursera[\"wilson_score\"] = df_coursera.apply(lambda row: wilson_score(row[\"rating\"], row[\"num_review\"]), axis=1)\n",
    "\n",
    "        df_coursera[\"description\"] = df_coursera[\"description\"].apply(lambda x: \"list \" + str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").strip())\n",
    "\n",
    "        df_coursera = df_coursera.drop(columns = [\"course_skill\", \"difficulty\"])\n",
    "        # Output folder for saving HTML files\n",
    "        data_folder = \"coursera_cleaned_df\"\n",
    "        os.makedirs(data_folder, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "        df_coursera.to_csv(f\"{data_folder}/{filename}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950433cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Udemy Data Cleaning\n",
    "# Coursera Data Cleaning and None Values Handling\n",
    "\n",
    "data_dir = \"./udemy_df\"\n",
    "\n",
    "# Loop through all files\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        \n",
    "        job_title = filename.split(\".\")[0]\n",
    "\n",
    "        df_udemy = pd.read_csv(f\"{data_dir}/{filename}\")\n",
    "\n",
    "\n",
    "        # Fill None\n",
    "        df_udemy[\"rating\"] = df_udemy[\"rating\"].fillna(df_udemy[\"rating\"].mean())\n",
    "        df_udemy[\"num_review\"] = df_udemy[\"num_review\"].fillna(0)\n",
    "        df_udemy[\"difficulty\"] = df_udemy[\"difficulty\"].fillna(\"All Levels\")\n",
    "        df_udemy[\"num_lecture\"] = df_udemy[\"num_lecture\"].fillna(1)\n",
    "        df_udemy[\"duration\"] = df_udemy[\"duration\"].fillna(df_udemy[\"duration\"].mode()[0])\n",
    "        df_udemy[\"price\"] = df_udemy[\"price\"].fillna(df_udemy[\"price\"].mode()[0])\n",
    "\n",
    "        # Data type\n",
    "        df_udemy[\"description\"] = df_udemy[\"course_description\"].fillna(\"\")\n",
    "        df_udemy[\"num_review\"] = df_udemy[\"num_review\"].astype(int)\n",
    "        df_udemy['difficulty_numeric'] = df_udemy['difficulty'].map(difficulty_mapping)\n",
    "        conversion_factors = {\n",
    "            'lectures': 1,\n",
    "            'questions': 0.1,\n",
    "            'Expert': 10\n",
    "        }\n",
    "        conversion_factors = {\n",
    "            'lectures': 1,\n",
    "            'questions': 0.1,\n",
    "            'Expert': 10\n",
    "        }\n",
    "\n",
    "        # Extract the numeric part and unit from `num_lecture`\n",
    "        df_udemy[['num_value', 'unit']] = df_udemy['num_lecture'].str.extract(r'(\\d+)\\s*([a-zA-Z]+)')\n",
    "        # Convert `num_value` to numeric, replacing errors with NaN\n",
    "        df_udemy['num_value'] = pd.to_numeric(df_udemy['num_value'], errors='coerce')\n",
    "        # Fill missing values in 'num_value' with 10 for Expert\n",
    "        df_udemy['num_value'] = df_udemy['num_value'].fillna(10)\n",
    "        # Apply conversion factors safely, ensuring no NaN values\n",
    "        df_udemy['num_lecture'] = df_udemy.apply(\n",
    "            lambda row: int(round(row['num_value'] * conversion_factors.get(row['unit'], 1))) if pd.notna(row['num_value']) else 0,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        def is_certificate(title):\n",
    "            return \"Certificate\" if isinstance(title, str) and \"certif\" in title.lower().strip() else \"Course\"\n",
    "\n",
    "        df_udemy[\"course_type\"] = df_udemy[\"title\"].apply(is_certificate)\n",
    "        df_udemy.loc[df_udemy[\"course_type\"] == \"Course\", \"course_type\"] = df_udemy.loc[df_udemy[\"course_type\"] == \"Course\", \"course_description\"].apply(is_certificate)\n",
    "        df_udemy.loc[df_udemy[\"course_type\"] == \"Certificate\", \"difficulty_numeric\"] = 3.0\n",
    "\n",
    "        # Extract the numeric value before \"total hours\"\n",
    "        df_udemy['duration'] = df_udemy['duration'].str.extract(r'([\\d\\.]+)')  # Extracts the numeric part\n",
    "        # Convert to float\n",
    "        df_udemy['duration'] = pd.to_numeric(df_udemy['duration'], errors='coerce')\n",
    "\n",
    "        # Ensure 'price' is a string type before extraction\n",
    "        df_udemy['price'] = df_udemy['price'].astype(str)\n",
    "        # Extract numeric values from 'price' (handling cases with currency symbols like \"US124.99\")\n",
    "        df_udemy['price'] = df_udemy['price'].str.extract(r'([\\d]+\\.?\\d*)')  # Matches numbers with decimals\n",
    "        # Convert to float\n",
    "        df_udemy['price'] = pd.to_numeric(df_udemy['price'], errors='coerce')\n",
    "        df_udemy['price'] = df_udemy['price'].fillna(df_udemy['price'].mean())\n",
    "        df_udemy[\"wilson_score\"] = df_udemy.apply(lambda row: wilson_score(row[\"rating\"], row[\"num_review\"]), axis=1)\n",
    "\n",
    "        df_udemy = df_udemy.drop(columns = ['num_value', 'unit', \"num_lecture\", \"course_description\", \"difficulty\"])\n",
    "        # Output folder for saving HTML files\n",
    "        data_folder = \"udemy_cleaned_df\"\n",
    "        os.makedirs(data_folder, exist_ok=True)  # Ensure folder exists\n",
    "        df_udemy.to_csv(f\"{data_folder}/{filename}\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca746893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5060 entries, 0 to 5165\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   skill       5060 non-null   object \n",
      " 1   link        2392 non-null   object \n",
      " 2   image_link  5060 non-null   object \n",
      " 3   author      5060 non-null   object \n",
      " 4   title       5060 non-null   object \n",
      " 5   price       5060 non-null   float64\n",
      " 6   publisher   5060 non-null   object \n",
      " 7   language    5060 non-null   object \n",
      " 8   num_page    5060 non-null   int32  \n",
      " 9   isbn        5060 non-null   object \n",
      " 10  rankings    5060 non-null   object \n",
      " 11  rating      5060 non-null   float64\n",
      " 12  num_rating  5060 non-null   int64  \n",
      "dtypes: float64(2), int32(1), int64(1), object(9)\n",
      "memory usage: 533.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Textbook Data Cleaning\n",
    "df_textbook = pd.read_csv(\"./unprocessed-df/df_textbook.csv\").iloc[:, 1:]\n",
    "# Fill None\n",
    "df_textbook = df_textbook.dropna(subset=['title'])\n",
    "df_textbook.loc[:, \"author\"] = df_textbook[\"author\"].fillna(\"Unknown\")\n",
    "df_textbook.loc[:, \"publisher\"] = df_textbook[\"publisher\"].fillna(\"Unknown\")\n",
    "df_textbook.loc[:, \"isbn\"] = df_textbook[\"isbn\"].fillna(\"Unknown\")\n",
    "df_textbook.loc[:, \"rating\"] = df_textbook[\"rating\"].fillna(df_textbook[\"rating\"].min())\n",
    "df_textbook.loc[:, \"language\"] = df_textbook[\"language\"].fillna(\"Unknown\")\n",
    "\n",
    "# Clean price, num_page, and num_rating, rankings\n",
    "df_textbook.loc[:, \"rankings\"] = df_textbook[\"rankings\"].apply(str_to_list)\n",
    "\n",
    "# Convert 'price' to float\n",
    "df_textbook['price'] = df_textbook['price'].fillna(\"$0\")\n",
    "df_textbook['price'] = df_textbook['price'].apply(lambda x: x.split()[0].replace(\"$\", \"\").replace(\",\",\"\")).astype(float)\n",
    "\n",
    "# Calculate mean and standard deviation of existing prices\n",
    "mean_price = df_textbook['price'].mean()\n",
    "std_price = df_textbook['price'].std()\n",
    "# Reduce the variation by scaling down the standard deviation\n",
    "scaled_std = std_price * 0.3  # Reduce variation (adjust factor as needed)\n",
    "# Generate different normally distributed values for each missing price\n",
    "nan_indices = df_textbook['price'].isna()\n",
    "random_prices = np.random.normal(loc=mean_price, scale=scaled_std, size=nan_indices.sum())\n",
    "# Ensure non-negative values and round to 2 decimal places\n",
    "random_prices = np.abs(random_prices)  # Make sure values are non-negative\n",
    "random_prices = np.round(random_prices, 2)  # Round to 2 decimal places\n",
    "# Assign generated prices to NaN values in the DataFrame\n",
    "df_textbook.loc[nan_indices, 'price'] = random_prices\n",
    "\n",
    "# Extract numeric values from 'num_page'\n",
    "df_textbook['num_page'] = df_textbook['num_page'].str.extract(r'(\\d+)')\n",
    "# Convert to float first to handle NaN values\n",
    "df_textbook['num_page'] = pd.to_numeric(df_textbook['num_page'], errors='coerce')\n",
    "# Fill NaN values with the mean number of pages, then convert to int\n",
    "df_textbook['num_page'] = df_textbook['num_page'].fillna(df_textbook['num_page'].mean()).astype(int)\n",
    "\n",
    "def extract_number(r):\n",
    "    if isinstance(r, str):  # Ensure it's a string\n",
    "        num_part = r.split()[0]  # Take the first part of the string\n",
    "        num_part = num_part.replace(\",\", \"\")  # Remove commas\n",
    "        if num_part.isdigit():  # Check if it's now a valid number\n",
    "            return int(num_part)\n",
    "    return 0  # Default to 0 for non-numeric values\n",
    "# Apply function to the column\n",
    "df_textbook[\"num_rating\"] = df_textbook[\"num_rating\"].apply(extract_number)\n",
    "\n",
    "df_textbook.to_csv(\"cleaned-df/df_textbook.csv\", index=False)\n",
    "\n",
    "df_textbook.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dce2736",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './unprocessed-df/df_youtube.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Youtube Data Cleaning\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_youtube = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./unprocessed-df/df_youtube.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.iloc[:, \u001b[32m1\u001b[39m:]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Fill None\u001b[39;00m\n\u001b[32m      5\u001b[39m df_youtube.loc[:, \u001b[33m\"\u001b[39m\u001b[33mthumbnail_link\u001b[39m\u001b[33m\"\u001b[39m] = df_youtube[\u001b[33m\"\u001b[39m\u001b[33mthumbnail_link\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\我的堆\\vscode_workspace\\243-Career-Roadmap\\backend\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\我的堆\\vscode_workspace\\243-Career-Roadmap\\backend\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\我的堆\\vscode_workspace\\243-Career-Roadmap\\backend\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\我的堆\\vscode_workspace\\243-Career-Roadmap\\backend\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\我的堆\\vscode_workspace\\243-Career-Roadmap\\backend\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './unprocessed-df/df_youtube.csv'"
     ]
    }
   ],
   "source": [
    "# Youtube Data Cleaning\n",
    "df_youtube = pd.read_csv(\"./unprocessed-df/df_youtube.csv\").iloc[:, 1:]\n",
    "\n",
    "# Fill None\n",
    "df_youtube.loc[:, \"thumbnail_link\"] = df_youtube[\"thumbnail_link\"].fillna(\"Unknown\")\n",
    "df_youtube.loc[:, \"num_views\"] = df_youtube[\"num_views\"].fillna(\"Unknown\")\n",
    "df_youtube.loc[:, \"snippet\"] = df_youtube[\"snippet\"].fillna(\"Unknown\")\n",
    "df_youtube.loc[:, \"chapter\"] = df_youtube[\"chapter\"].fillna(1)\n",
    "df_youtube.loc[:, 'series'] = df_youtube['series'].apply(str_to_list)\n",
    "df_youtube.loc[:, 'series'] = df_youtube['series'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df_youtube[\"chapter\"] = df_youtube[\"chapter\"].astype(int)\n",
    "\n",
    "# Clean age, duration, num_views\n",
    "\n",
    "# Define a function to extract and convert views\n",
    "def convert_views(value):\n",
    "    import re\n",
    "    value = str(value).strip()  # Ensure it's a string and remove extra spaces\n",
    "\n",
    "    # Check if the value ends with \"views\"\n",
    "    if not value.endswith(\"views\"):\n",
    "        return 0  # If not a valid view count, return 0\n",
    "    # Extract the numeric part and the suffix (K, M, etc.)\n",
    "    match = re.match(r'([\\d\\.]+)([KkMm]?) views', value)\n",
    "    if match:\n",
    "        num, suffix = match.groups()\n",
    "        num = float(num)  # Convert to float for decimal values\n",
    "        # Convert K (thousands) and M (millions) to proper numbers\n",
    "        if suffix == 'K' or suffix == 'k':\n",
    "            return int(num * 1_000)\n",
    "        elif suffix == 'M' or suffix == 'm':\n",
    "            return int(num * 1_000_000)\n",
    "        else:\n",
    "            return int(num)  # If no suffix, return as integer\n",
    "    else:\n",
    "        return 0  # Default case\n",
    "# Apply function to the column in df_youtube\n",
    "df_youtube['num_views'] = df_youtube['num_views'].apply(convert_views)\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define function to convert time since posted into years\n",
    "def convert_to_years(value):\n",
    "    value = str(value).strip()  # Ensure it's a string and remove extra spaces\n",
    "    # Check if the value ends with \"ago\" (valid time indicator)\n",
    "    if not value.endswith(\"ago\"):\n",
    "        return None  # If not a valid date format, return None\n",
    "    # Match the number and time unit\n",
    "    match = re.match(r'(\\d+)\\s*(year|minute|hour|day|month)s?\\s+ago', value)\n",
    "    if match:\n",
    "        num, unit = int(match.group(1)), match.group(2)\n",
    "        # Convert different time units into years\n",
    "        if unit == 'year':\n",
    "            return num\n",
    "        elif unit == 'month':\n",
    "            return round(num / 12)  # Approximate months to years\n",
    "        elif unit == 'day':\n",
    "            return round(num / 365)  # Approximate days to years\n",
    "        elif unit == 'hour':\n",
    "            return 0  # Hours are within the same year\n",
    "        elif unit == 'minute':\n",
    "            return 0  # Minutes are within the same year\n",
    "    return 0  # Default to 0 years for unhandled cases\n",
    "# Apply function to the column in df_youtube\n",
    "df_youtube['age'] = df_youtube['age'].apply(convert_to_years)\n",
    "df_youtube['age'] = df_youtube['age'].fillna(0)\n",
    "\n",
    "# Define function to convert duration into seconds\n",
    "def convert_to_seconds(value):\n",
    "    value = str(value).strip()  # Ensure it's a string and remove extra spaces\n",
    "    # Handle special cases (SHORTS, UPCOMING, and irregular formats)\n",
    "    if value in [\"SHORTS\", \"UPCOMING\"]:\n",
    "        return 3 * 60  # Assume 3 minutes (180 seconds) for Shorts and Upcoming videos\n",
    "    # Match durations in HH:MM:SS, MM:SS, or SS formats\n",
    "    match = re.match(r'(?:(\\d+):)?(\\d+):(\\d+)$', value)  # Matches HH:MM:SS or MM:SS\n",
    "    if match:\n",
    "        hours = int(match.group(1)) if match.group(1) else 0\n",
    "        minutes = int(match.group(2))\n",
    "        seconds = int(match.group(3))\n",
    "        return hours * 3600 + minutes * 60 + seconds  # Convert to total seconds\n",
    "    return 3 * 60  # Default to 3 minutes if format is unrecognized\n",
    "\n",
    "# Apply function to the duration column in df_youtube\n",
    "df_youtube['duration_seconds'] = df_youtube['duration'].apply(convert_to_seconds)\n",
    "df_youtube = df_youtube.drop(columns=[\"duration\"])\n",
    "\n",
    "df_youtube.to_csv(\"cleaned-df/df_youtube.csv\", index=False)\n",
    "\n",
    "df_youtube.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
